# -*- coding: utf-8 -*-
"""ECG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JvaFBZfkIJltgOHnUKGkALuEgJz-gxmp
"""

# 1. Install and Import
!pip install wfdb

import os
import random
import numpy as np
import wfdb
from tensorflow.keras.utils import Sequence
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt



# 2. Download MIT-BIH
wfdb.dl_database("mitdb", dl_dir="mitdb")

available = sorted([f.split('.')[0] for f in os.listdir("mitdb") if f.endswith(".hea")])
print("Available Records:", available)



# 3. Load record function
def load_record(record_id):
    record = wfdb.rdrecord(f"mitdb/{record_id}")
    ann = wfdb.rdann(f"mitdb/{record_id}", "atr")

    ecg = record.p_signal[:, 0]  # Lead II default
    ecg = (ecg - ecg.min()) / (ecg.max() - ecg.min())  # normalize

    return ecg, ann



# 4. Data Generator

class MITBIHGenerator(Sequence):

    def __init__(self, record_list, batch_size=32, window_size=200, shuffle=True):
        self.record_list = record_list
        self.batch_size = batch_size
        self.window_size = window_size
        self.shuffle = shuffle

        self.normal_beats = ['N', 'L', 'R']
        self.samples = []


        for r in record_list:
            ecg, ann = load_record(r)
            for s in range(0, len(ecg) - window_size, window_size):
                self.samples.append((r, s))

        if shuffle:
            random.shuffle(self.samples)

    def __len__(self):
        return len(self.samples) // self.batch_size

    def __getitem__(self, idx):
        batch = self.samples[idx*self.batch_size:(idx+1)*self.batch_size]

        X = np.zeros((len(batch), self.window_size, 1))
        y = np.zeros((len(batch), 1))

        for i, (rec, start) in enumerate(batch):

            ecg, ann = load_record(rec)
            window = ecg[start:start+self.window_size]
            X[i] = window.reshape(-1, 1)

            mask = (ann.sample >= start) & (ann.sample < start+self.window_size)
            if mask.any():
                symbols = np.array(ann.symbol)
                beats = symbols[mask]
                if any(bt not in self.normal_beats for bt in beats):
                    y[i] = 1
                else:
                    y[i] = 0
            else:
                y[i] = 0

        return X, y

    def on_epoch_end(self):
        if self.shuffle:
            random.shuffle(self.samples)



# 5. Build CNN Model

def build_model(window_size=200):
    model = models.Sequential([
        layers.Conv1D(32, 5, activation='relu', padding='same', input_shape=(window_size,1)),
        layers.MaxPooling1D(2),

        layers.Conv1D(64, 5, activation='relu', padding='same'),
        layers.MaxPooling1D(2),

        layers.Conv1D(128, 3, activation='relu', padding='same'),
        layers.MaxPooling1D(2),

        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model


# 6. Train/Test split based on records
random.shuffle(available)

train_records = available[:int(0.8 * len(available))]
test_records  = available[int(0.8 * len(available)):]

print("Train Records:", train_records)
print("Test Records :", test_records)

train_gen = MITBIHGenerator(train_records, batch_size=32)
test_gen  = MITBIHGenerator(test_records, batch_size=32, shuffle=False)



# 7. Train the model
model = build_model()
model.fit(train_gen, validation_data=test_gen, epochs=10)

loss, acc = model.evaluate(test_gen)
print("\nFinal Test Accuracy:", acc)